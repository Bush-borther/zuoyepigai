# Smart Exam Grading System
# æ™ºèƒ½è¯•å·æ‰¹æ”¹ç³»ç»Ÿ

[English](#english) | [ä¸­æ–‡](#chinese)

---

## English

### Overview

An intelligent exam grading system that uses OCR and LLM to automatically grade handwritten test papers and generate marked PDFs.

### Features

- ğŸ“ **OCR Recognition**: Extracts text from scanned exam papers using PaddleOCR
- ğŸ¤– **AI Grading**: Uses LLM to intelligently grade answers
- âœ… **Visual Feedback**: Marks correct answers with âœ“ and incorrect ones with âœ—
- ğŸ“„ **PDF Generation**: Creates downloadable graded PDFs
- ğŸ¯ **Spatial Segmentation**: Automatically detects question regions
- âš™ï¸ **Flexible Configuration**: Supports multiple LLM providers (OpenAI, DeepSeek, NVIDIA, etc.)

### Tech Stack

**Backend:**
- FastAPI
- PaddleOCR
- Pillow (Image Processing)
- Python 3.10+

**Frontend:**
- React + TypeScript
- Vite
- Modern CSS

### Installation

#### Prerequisites

- Python 3.10 or higher
- Node.js 16 or higher
- npm or yarn

#### Backend Setup

```bash
# Install Python dependencies
pip install -r requirements.txt

# Create necessary directories
mkdir -p backend/static/uploads backend/static/results
```

#### Frontend Setup

```bash
cd frontend
npm install
```

#### Environment Configuration (Optional)

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your LLM API key
# If not configured, the system runs in MOCK mode
```

### Usage

#### Start Backend

```bash
# From project root
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

#### Start Frontend

```bash
cd frontend
npm run dev -- --host
```

#### Access Application

Open your browser and navigate to: `http://localhost:5173`

### Configuration

#### LLM API Configuration

You can configure LLM API in two ways:

1. **Environment Variables** (`.env` file):
```env
LLM_API_KEY=your_api_key
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o
```

2. **Web Interface**: Click the settings icon (âš™ï¸) in the top-right corner

#### Supported LLM Providers

- OpenAI (GPT-4, GPT-3.5)
- DeepSeek
- NVIDIA NIM
- Any OpenAI-compatible API

### Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/              # API endpoints
â”‚   â”œâ”€â”€ service/          # Business logic
â”‚   â”‚   â”œâ”€â”€ ocr_service.py       # OCR processing
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # LLM integration
â”‚   â”‚   â”œâ”€â”€ grading_service.py   # Grading logic
â”‚   â”‚   â””â”€â”€ image_processor.py   # Image marking
â”‚   â”œâ”€â”€ static/           # Static files
â”‚   â””â”€â”€ main.py           # Application entry
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/   # React components
â”‚       â””â”€â”€ App.tsx       # Main application
â””â”€â”€ README.md
```

### How It Works

1. **Upload**: User uploads a scanned exam paper image
2. **OCR**: PaddleOCR extracts all text and coordinates
3. **Segmentation**: System detects question regions by finding question numbers (1, 2, 3...)
4. **Grading**: Each region is sent to LLM for grading
5. **Marking**: Draws âœ“ or âœ— marks on the image
6. **PDF**: Generates a downloadable PDF with marks

### License

MIT

---

## Chinese

### æ¦‚è¿°

ä¸€ä¸ªæ™ºèƒ½è¯•å·æ‰¹æ”¹ç³»ç»Ÿï¼Œä½¿ç”¨ OCR å’Œå¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨æ‰¹æ”¹æ‰‹å†™è¯•å·å¹¶ç”Ÿæˆæ ‡æ³¨ PDFã€‚

### åŠŸèƒ½ç‰¹æ€§

- ğŸ“ **OCR è¯†åˆ«**ï¼šä½¿ç”¨ PaddleOCR ä»æ‰«æè¯•å·ä¸­æå–æ–‡å­—
- ğŸ¤– **AI åˆ¤é¢˜**ï¼šä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½åˆ¤æ–­ç­”æ¡ˆå¯¹é”™
- âœ… **è§†è§‰åé¦ˆ**ï¼šåœ¨æ­£ç¡®ç­”æ¡ˆä¸Šæ‰“ âœ“ï¼Œé”™è¯¯ç­”æ¡ˆä¸Šæ‰“ âœ—
- ğŸ“„ **PDF ç”Ÿæˆ**ï¼šåˆ›å»ºå¯ä¸‹è½½çš„æ‰¹æ”¹å PDF
- ğŸ¯ **ç©ºé—´åˆ†å‰²**ï¼šè‡ªåŠ¨æ£€æµ‹é¢˜ç›®åŒºåŸŸ
- âš™ï¸ **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§ LLM æä¾›å•†ï¼ˆOpenAIã€DeepSeekã€NVIDIA ç­‰ï¼‰

### æŠ€æœ¯æ ˆ

**åç«¯ï¼š**
- FastAPI
- PaddleOCR
- Pillowï¼ˆå›¾åƒå¤„ç†ï¼‰
- Python 3.10+

**å‰ç«¯ï¼š**
- React + TypeScript
- Vite
- ç°ä»£ CSS

### å®‰è£…

#### ç¯å¢ƒè¦æ±‚

- Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- Node.js 16 æˆ–æ›´é«˜ç‰ˆæœ¬
- npm æˆ– yarn

#### åç«¯è®¾ç½®

```bash
# å®‰è£… Python ä¾èµ–
pip install -r requirements.txt

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p backend/static/uploads backend/static/results
```

#### å‰ç«¯è®¾ç½®

```bash
cd frontend
npm install
```

#### ç¯å¢ƒé…ç½®ï¼ˆå¯é€‰ï¼‰

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env å¹¶æ·»åŠ æ‚¨çš„ LLM API å¯†é’¥
# å¦‚æœä¸é…ç½®ï¼Œç³»ç»Ÿå°†ä»¥ MOCK æ¨¡å¼è¿è¡Œ
```

### ä½¿ç”¨æ–¹æ³•

#### å¯åŠ¨åç«¯

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

#### å¯åŠ¨å‰ç«¯

```bash
cd frontend
npm run dev -- --host
```

#### è®¿é—®åº”ç”¨

åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼š`http://localhost:5173`

### é…ç½®è¯´æ˜

#### LLM API é…ç½®

å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼é…ç½® LLM APIï¼š

1. **ç¯å¢ƒå˜é‡**ï¼ˆ`.env` æ–‡ä»¶ï¼‰ï¼š
```env
LLM_API_KEY=your_api_key
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o
```

2. **ç½‘é¡µç•Œé¢**ï¼šç‚¹å‡»å³ä¸Šè§’çš„è®¾ç½®å›¾æ ‡ï¼ˆâš™ï¸ï¼‰

#### æ”¯æŒçš„ LLM æä¾›å•†

- OpenAIï¼ˆGPT-4ã€GPT-3.5ï¼‰
- DeepSeek
- NVIDIA NIM
- ä»»ä½•å…¼å®¹ OpenAI API çš„æœåŠ¡

### é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/              # API ç«¯ç‚¹
â”‚   â”œâ”€â”€ service/          # ä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ ocr_service.py       # OCR å¤„ç†
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # LLM é›†æˆ
â”‚   â”‚   â”œâ”€â”€ grading_service.py   # åˆ¤é¢˜é€»è¾‘
â”‚   â”‚   â””â”€â”€ image_processor.py   # å›¾åƒæ ‡æ³¨
â”‚   â”œâ”€â”€ static/           # é™æ€æ–‡ä»¶
â”‚   â””â”€â”€ main.py           # åº”ç”¨å…¥å£
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/   # React ç»„ä»¶
â”‚       â””â”€â”€ App.tsx       # ä¸»åº”ç”¨
â””â”€â”€ README.md
```

### å·¥ä½œåŸç†

1. **ä¸Šä¼ **ï¼šç”¨æˆ·ä¸Šä¼ æ‰«æçš„è¯•å·å›¾ç‰‡
2. **OCR**ï¼šPaddleOCR æå–æ‰€æœ‰æ–‡å­—å’Œåæ ‡
3. **åˆ†å‰²**ï¼šç³»ç»Ÿé€šè¿‡æ£€æµ‹é¢˜å·ï¼ˆ1ã€2ã€3...ï¼‰æ¥è¯†åˆ«é¢˜ç›®åŒºåŸŸ
4. **åˆ¤é¢˜**ï¼šæ¯ä¸ªåŒºåŸŸå‘é€ç»™ LLM è¿›è¡Œåˆ¤é¢˜
5. **æ ‡æ³¨**ï¼šåœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶ âœ“ æˆ– âœ— æ ‡è®°
6. **PDF**ï¼šç”Ÿæˆå¯ä¸‹è½½çš„å¸¦æ ‡è®° PDF

### è®¸å¯è¯

MIT
